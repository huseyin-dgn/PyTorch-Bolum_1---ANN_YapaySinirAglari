{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4ef372",
   "metadata": {},
   "source": [
    "# Bu .ipynb dosyasında öncelikle model tasarımına bakacağız.Geçen repoda söylediğim gibi Keras reposuna bakmayı unutmayınız.\n",
    "\n",
    "*  `\"https://github.com/huseyin-dgn/Deep-Learning-Fundamentals\" `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a6183",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e3932",
   "metadata": {},
   "source": [
    "# KERAS \n",
    "\n",
    "## 🔹 1. Katman Tanımlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60916767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hdgn5\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=30, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c362c",
   "metadata": {},
   "source": [
    "* Burada Dense = tam bağlı katman.\n",
    "\n",
    "* 64 → nöron sayısı\n",
    "\n",
    "* activation='relu' → aktivasyon fonksiyonu\n",
    "\n",
    "* input_dim=30 → giriş boyutu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446370e3",
   "metadata": {},
   "source": [
    "# PYTORCH\n",
    "\n",
    "## 🔹 1. Katman Tanımlama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e374752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)   # Dense(64, input_dim=input_size)\n",
    "        self.fc2 = nn.Linear(64, 32)           # Dense(32)\n",
    "        self.fc3 = nn.Linear(32, 1)            # Dense(1)\n",
    "\n",
    "        self.relu = nn.ReLU()                  # aktivasyon fonksiyonları ayrı tanımlanır\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))             # Dense + ReLU\n",
    "        x = self.relu(self.fc2(x))             # Dense + ReLU\n",
    "        x = self.sigmoid(self.fc3(x))          # Dense + Sigmoid\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f61fb",
   "metadata": {},
   "source": [
    "###   PyTorch’ta Model Tanımı: nn.Module\n",
    "\n",
    "Her PyTorch modeli aslında nn.Module sınıfından türetilir.\n",
    "Biz kendi ANN’imizi yazarken, nn.Module’u miras alıyoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc07123",
   "metadata": {},
   "source": [
    "## 🔹 2. __init__ Ne İşe Yarar?\n",
    "\n",
    "__init__, modelin katmanlarını tanımladığımız yerdir.\n",
    "Yani ağın mimarisi burada kurulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.fc1 = nn.Linear(input_size, 64)\n",
    "self.fc2 = nn.Linear(64, 32)\n",
    "self.fc3 = nn.Linear(32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05763cf3",
   "metadata": {},
   "source": [
    "* Burada self.fc1 dediğimizde → ANN sınıfına ait bir özellik (attribute) oluşturuyoruz.\n",
    "\n",
    "* Yani artık model objemizin içinde fc1, fc2, fc3 katmanları var.\n",
    "\n",
    "* Eğer self yazmazsak, bu katmanlar sınıfın dışında tanımlanır ve model bunları hatırlamaz. Eğitimde kullanamaz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd7616",
   "metadata": {},
   "source": [
    "## 🔹 3. forward ve self\n",
    "\n",
    "* İleri besleme fonksiyonu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e3895",
   "metadata": {},
   "source": [
    "Burada da yine self.fc1 yazıyoruz çünkü bizim sınıfa ait katmanı çağırıyoruz.\n",
    "\n",
    "* self.fc1 → modelin içinde saklanan katman\n",
    "\n",
    "* fc1 deseydik → Python “böyle bir değişken yok” diye hata verecekti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73036c24",
   "metadata": {},
   "source": [
    "## 🔹 4. Basit Benzetme\n",
    "\n",
    "Düşün ki bir araba fabrikası yapıyorsun:\n",
    "\n",
    "* __init__ → arabayı tasarladığın yer (motor, tekerlek, koltukları tanımlarsın).\n",
    "\n",
    "* self → bu parçaların o arabaya ait olduğunu gösterir.\n",
    "\n",
    "* forward → arabayı çalıştırıp yolculuk yaptığın yer (parçaları sırayla kullanırsın).\n",
    "\n",
    "* Eğer self demezsen, parçalar fabrikanın içinde kaybolur, arabanın üstüne takılmaz 🚗"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd8b9e",
   "metadata": {},
   "source": [
    "## 🔹 5. super() Ne Demek?\n",
    "\n",
    "* Python’da super() = ebeveyn (üst) sınıfı çağırmak demektir.\n",
    "* Bizim ANN modelimiz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768d0be",
   "metadata": {},
   "source": [
    "#### Burada:\n",
    "\n",
    "* ANN = bizim oluşturduğumuz sınıf\n",
    "\n",
    "* nn.Module = bunun ebeveyni (parent class)\n",
    "\n",
    "* super(ANN, self).__init__() = ebeveynin kurulum fonksiyonunu (__init__) da çalıştır\n",
    "\n",
    "### 🔹 6. Neden Önemli?\n",
    "\n",
    "Çünkü nn.Module sınıfı kendi içinde birçok özellik taşıyor:\n",
    "\n",
    "* Modelin katmanlarını kaydeder\n",
    "\n",
    "* Parametreleri (weights, bias) izler\n",
    "\n",
    "* model.parameters() gibi fonksiyonların çalışmasını sağlar\n",
    "\n",
    "* GPU/CPU’ya model taşımayı (.to(device)) mümkün kılar\n",
    "\n",
    "* Eğer super() çağırmazsak → bu mekanizmalar devreye girmez ❌ ve modelin eğitiminde sorun çıkar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66010a17",
   "metadata": {},
   "source": [
    "## 🔹 7. Özet\n",
    "\n",
    "* __init__ = modelin katmanlarını tanımladığın kurulum yeri\n",
    "\n",
    "* self = modelin kendisine ait şeyleri saklamanı sağlar\n",
    "\n",
    "* forward = verinin katmanlardan nasıl geçeceğini tarif eder\n",
    "\n",
    "* super() = ebeveyn sınıfın (nn.Module) tüm özelliklerini aktif etmek\n",
    "\n",
    "👉 Yani PyTorch’ta self ve __init__ kullanmamızın sebebi, modelin parametrelerini (katmanları) sınıfa bağlayıp eğitim boyunca takip edebilmek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6246ca6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b03357",
   "metadata": {},
   "source": [
    "# 👌BASİT BİR ANN MODELİ 👌"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40401a",
   "metadata": {},
   "source": [
    "### !!!! Eğer self ve init kullanımlarında sorun yaşıyorsanız.Lütfen şu dosyaya gidiniz\n",
    "\n",
    "* `ANN\\Tensorler ve OOP\\Self_ve_İnit_Fonksiyonları.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c802aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN,self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b1787",
   "metadata": {},
   "source": [
    "| Parametre     | PyTorch’taki karşılığı | Açıklama                                                 |\n",
    "| ------------- | ---------------------- | -------------------------------------------------------- |\n",
    "| `self`        | Nesne referansı        | Katmanları ve parametreleri model nesnesine bağlar       |\n",
    "| `__init__`    | Kurucu fonksiyon       | Katmanları ve model parametrelerini başlatır             |\n",
    "| `input_size`  | Kullanıcı girdisi      | Katman boyutlarını belirler, ağırlık matrisini oluşturur |\n",
    "| Weight & Bias | Katmanın parametreleri | Modelin öğrenebildiği değerler, eğitimle güncellenir     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69183e3a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79ef2f",
   "metadata": {},
   "source": [
    "# PyTorch Modelini Güçlendirecek Ekstra Modüller\n",
    "\n",
    "PyTorch modelimizde kullanabileceğimiz bazı ek modüller ve teknikler:\n",
    "\n",
    "---\n",
    "\n",
    "## 1️⃣ Dropout\n",
    "- Eğitim sırasında bazı nöronları **rastgele kapatır**.\n",
    "- Amaç: **Overfitting’i azaltmak**, modelin genellemesini sağlamak.\n",
    "\n",
    "```python\n",
    "self.dropout = nn.Dropout(p=0.2)  # %20 nöron rastgele kapatılır\n",
    "x = self.relu(self.fc1(x))\n",
    "x = self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c11714",
   "metadata": {},
   "source": [
    "## 2️⃣ Batch Normalization (BatchNorm)\n",
    "\n",
    "- Katman çıkışlarını normalize ederek **eğitimi stabil ve hızlı hale getirir**.\n",
    "- Derin ağlarda özellikle **öğrenme hızını artırır** ve **vanishing/exploding gradient** sorunlarını azaltır.\n",
    "\n",
    "```python\n",
    "self.bn1 = nn.BatchNorm1d(64)  # fc1 çıkışı 64 nöron\n",
    "x = self.relu(self.bn1(self.fc1(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80473de",
   "metadata": {},
   "source": [
    "## 3️⃣ Weight Initialization\n",
    "\n",
    "- Katman ağırlıkları genellikle **rastgele başlatılır**, ama kontrol etmek isteyebilirsin.\n",
    "- Örnek: uniform dağılım ile başlatmak\n",
    "\n",
    "```python\n",
    "nn.init.uniform_(self.fc1.weight, a=-0.1, b=0.1)\n",
    "nn.init.zeros_(self.fc1.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea70fd",
   "metadata": {},
   "source": [
    "#### nn.init modülü ile:\n",
    "\n",
    "* uniform_ → belirli aralıkta başlatma\n",
    "\n",
    "* normal_ → ortalama ve standart sapmalı başlatma\n",
    "\n",
    "* xavier_uniform_, kaiming_normal_ → derin ağlar için özel yöntemler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e958",
   "metadata": {},
   "source": [
    "## 4️⃣ Aktivasyon Fonksiyonları\n",
    "\n",
    "- ReLU dışında farklı aktivasyonlar deneyebilirsin:\n",
    "  - `nn.Tanh()`\n",
    "  - `nn.LeakyReLU(0.1)`\n",
    "  - `nn.ELU()`\n",
    "  - `nn.Softmax(dim=1)`\n",
    "\n",
    "- Örnek kullanım:\n",
    "\n",
    "```python\n",
    "self.relu = nn.LeakyReLU(0.1)  # küçük negatif slope ile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229faeb",
   "metadata": {},
   "source": [
    "# 5️⃣ Özet Tablo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561f753",
   "metadata": {},
   "source": [
    "| Modül/Özellik     | Amaç                                      | Kullanım                           |\n",
    "| ----------------- | ----------------------------------------- | ---------------------------------- |\n",
    "| Dropout           | Overfitting’i azaltmak                    | `nn.Dropout(p)`                    |\n",
    "| BatchNorm         | Eğitim stabilitesi ve hız artırma         | `nn.BatchNorm1d(n)`                |\n",
    "| Weight Init       | Ağırlıkları belirli dağılım ile başlatmak | `nn.init.*`                        |\n",
    "| Farklı Aktivasyon | Modelin davranışını değiştirmek           | `nn.ReLU()`, `nn.LeakyReLU()`, ... |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e67a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EnhancedANN(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Gizli katman boyutları sabit\n",
    "        h1, h2, h3 = 128, 64, 32\n",
    "        layers = []\n",
    "\n",
    "        # 1. Katman\n",
    "        layers.append(nn.Linear(input_size, h1))\n",
    "        layers.append(nn.BatchNorm1d(h1))\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # 2. Katman\n",
    "        layers.append(nn.Linear(h1, h2))\n",
    "        layers.append(nn.BatchNorm1d(h2))\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # 3. Katman\n",
    "        layers.append(nn.Linear(h2, h3))\n",
    "        layers.append(nn.BatchNorm1d(h3))\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # Çıkış katmanı\n",
    "        layers.append(nn.Linear(h3, output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a7005",
   "metadata": {},
   "source": [
    "## Şimdi yukarıda bulunan bu modelin tekrarını ve karmaşasını düzeltelimmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a38823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CleanEnhancedANN(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Katman ve aktivasyonları tek bir fonksiyon ile oluştur\n",
    "        def linear_block(in_features, out_features, dropout):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_features, out_features),\n",
    "                nn.BatchNorm1d(out_features),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        \n",
    "        # Katmanları sırayla ekle\n",
    "        self.model = nn.Sequential(\n",
    "            linear_block(input_size, 128, dropout_p),\n",
    "            linear_block(128, 64, dropout_p),\n",
    "            linear_block(64, 32, dropout_p),\n",
    "            nn.Linear(32, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e41fd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
