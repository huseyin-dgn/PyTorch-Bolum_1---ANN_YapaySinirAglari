{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0b4ef372",
   "metadata": {},
   "source": [
    "# Bu .ipynb dosyasÄ±nda Ã¶ncelikle model tasarÄ±mÄ±na bakacaÄŸÄ±z.GeÃ§en repoda sÃ¶ylediÄŸim gibi Keras reposuna bakmayÄ± unutmayÄ±nÄ±z.\n",
    "\n",
    "*  `\"https://github.com/huseyin-dgn/Deep-Learning-Fundamentals\" `"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e6a6183",
   "metadata": {},
   "source": [
    "---------------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783e3932",
   "metadata": {},
   "source": [
    "# KERAS \n",
    "\n",
    "## ğŸ”¹ 1. Katman TanÄ±mlama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "60916767",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\hdgn5\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(64, input_dim=30, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267c362c",
   "metadata": {},
   "source": [
    "* Burada Dense = tam baÄŸlÄ± katman.\n",
    "\n",
    "* 64 â†’ nÃ¶ron sayÄ±sÄ±\n",
    "\n",
    "* activation='relu' â†’ aktivasyon fonksiyonu\n",
    "\n",
    "* input_dim=30 â†’ giriÅŸ boyutu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "446370e3",
   "metadata": {},
   "source": [
    "# PYTORCH\n",
    "\n",
    "## ğŸ”¹ 1. Katman TanÄ±mlama "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4e374752",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 64)   # Dense(64, input_dim=input_size)\n",
    "        self.fc2 = nn.Linear(64, 32)           # Dense(32)\n",
    "        self.fc3 = nn.Linear(32, 1)            # Dense(1)\n",
    "\n",
    "        self.relu = nn.ReLU()                  # aktivasyon fonksiyonlarÄ± ayrÄ± tanÄ±mlanÄ±r\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))             # Dense + ReLU\n",
    "        x = self.relu(self.fc2(x))             # Dense + ReLU\n",
    "        x = self.sigmoid(self.fc3(x))          # Dense + Sigmoid\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d8f61fb",
   "metadata": {},
   "source": [
    "###   PyTorchâ€™ta Model TanÄ±mÄ±: nn.Module\n",
    "\n",
    "Her PyTorch modeli aslÄ±nda nn.Module sÄ±nÄ±fÄ±ndan tÃ¼retilir.\n",
    "Biz kendi ANNâ€™imizi yazarken, nn.Moduleâ€™u miras alÄ±yoruz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acc07123",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 2. __init__ Ne Ä°ÅŸe Yarar?\n",
    "\n",
    "__init__, modelin katmanlarÄ±nÄ± tanÄ±mladÄ±ÄŸÄ±mÄ±z yerdir.\n",
    "Yani aÄŸÄ±n mimarisi burada kurulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5fd498",
   "metadata": {},
   "outputs": [],
   "source": [
    "self.fc1 = nn.Linear(input_size, 64)\n",
    "self.fc2 = nn.Linear(64, 32)\n",
    "self.fc3 = nn.Linear(32, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05763cf3",
   "metadata": {},
   "source": [
    "* Burada self.fc1 dediÄŸimizde â†’ ANN sÄ±nÄ±fÄ±na ait bir Ã¶zellik (attribute) oluÅŸturuyoruz.\n",
    "\n",
    "* Yani artÄ±k model objemizin iÃ§inde fc1, fc2, fc3 katmanlarÄ± var.\n",
    "\n",
    "* EÄŸer self yazmazsak, bu katmanlar sÄ±nÄ±fÄ±n dÄ±ÅŸÄ±nda tanÄ±mlanÄ±r ve model bunlarÄ± hatÄ±rlamaz. EÄŸitimde kullanamaz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2edd7616",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 3. forward ve self\n",
    "\n",
    "* Ä°leri besleme fonksiyonu:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4361f052",
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward(self, x):\n",
    "    x = self.fc1(x)\n",
    "    x = self.fc2(x)\n",
    "    x = self.fc3(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748e3895",
   "metadata": {},
   "source": [
    "Burada da yine self.fc1 yazÄ±yoruz Ã§Ã¼nkÃ¼ bizim sÄ±nÄ±fa ait katmanÄ± Ã§aÄŸÄ±rÄ±yoruz.\n",
    "\n",
    "* self.fc1 â†’ modelin iÃ§inde saklanan katman\n",
    "\n",
    "* fc1 deseydik â†’ Python â€œbÃ¶yle bir deÄŸiÅŸken yokâ€ diye hata verecekti"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73036c24",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 4. Basit Benzetme\n",
    "\n",
    "DÃ¼ÅŸÃ¼n ki bir araba fabrikasÄ± yapÄ±yorsun:\n",
    "\n",
    "* __init__ â†’ arabayÄ± tasarladÄ±ÄŸÄ±n yer (motor, tekerlek, koltuklarÄ± tanÄ±mlarsÄ±n).\n",
    "\n",
    "* self â†’ bu parÃ§alarÄ±n o arabaya ait olduÄŸunu gÃ¶sterir.\n",
    "\n",
    "* forward â†’ arabayÄ± Ã§alÄ±ÅŸtÄ±rÄ±p yolculuk yaptÄ±ÄŸÄ±n yer (parÃ§alarÄ± sÄ±rayla kullanÄ±rsÄ±n).\n",
    "\n",
    "* EÄŸer self demezsen, parÃ§alar fabrikanÄ±n iÃ§inde kaybolur, arabanÄ±n Ã¼stÃ¼ne takÄ±lmaz ğŸš—"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6abd8b9e",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 5. super() Ne Demek?\n",
    "\n",
    "* Pythonâ€™da super() = ebeveyn (Ã¼st) sÄ±nÄ±fÄ± Ã§aÄŸÄ±rmak demektir.\n",
    "* Bizim ANN modelimiz:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd7049",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN, self).__init__()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9768d0be",
   "metadata": {},
   "source": [
    "#### Burada:\n",
    "\n",
    "* ANN = bizim oluÅŸturduÄŸumuz sÄ±nÄ±f\n",
    "\n",
    "* nn.Module = bunun ebeveyni (parent class)\n",
    "\n",
    "* super(ANN, self).__init__() = ebeveynin kurulum fonksiyonunu (__init__) da Ã§alÄ±ÅŸtÄ±r\n",
    "\n",
    "### ğŸ”¹ 6. Neden Ã–nemli?\n",
    "\n",
    "Ã‡Ã¼nkÃ¼ nn.Module sÄ±nÄ±fÄ± kendi iÃ§inde birÃ§ok Ã¶zellik taÅŸÄ±yor:\n",
    "\n",
    "* Modelin katmanlarÄ±nÄ± kaydeder\n",
    "\n",
    "* Parametreleri (weights, bias) izler\n",
    "\n",
    "* model.parameters() gibi fonksiyonlarÄ±n Ã§alÄ±ÅŸmasÄ±nÄ± saÄŸlar\n",
    "\n",
    "* GPU/CPUâ€™ya model taÅŸÄ±mayÄ± (.to(device)) mÃ¼mkÃ¼n kÄ±lar\n",
    "\n",
    "* EÄŸer super() Ã§aÄŸÄ±rmazsak â†’ bu mekanizmalar devreye girmez âŒ ve modelin eÄŸitiminde sorun Ã§Ä±kar.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66010a17",
   "metadata": {},
   "source": [
    "## ğŸ”¹ 7. Ã–zet\n",
    "\n",
    "* __init__ = modelin katmanlarÄ±nÄ± tanÄ±mladÄ±ÄŸÄ±n kurulum yeri\n",
    "\n",
    "* self = modelin kendisine ait ÅŸeyleri saklamanÄ± saÄŸlar\n",
    "\n",
    "* forward = verinin katmanlardan nasÄ±l geÃ§eceÄŸini tarif eder\n",
    "\n",
    "* super() = ebeveyn sÄ±nÄ±fÄ±n (nn.Module) tÃ¼m Ã¶zelliklerini aktif etmek\n",
    "\n",
    "ğŸ‘‰ Yani PyTorchâ€™ta self ve __init__ kullanmamÄ±zÄ±n sebebi, modelin parametrelerini (katmanlarÄ±) sÄ±nÄ±fa baÄŸlayÄ±p eÄŸitim boyunca takip edebilmek."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6246ca6",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b03357",
   "metadata": {},
   "source": [
    "# ğŸ‘ŒBASÄ°T BÄ°R ANN MODELÄ° ğŸ‘Œ"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d40401a",
   "metadata": {},
   "source": [
    "### !!!! EÄŸer self ve init kullanÄ±mlarÄ±nda sorun yaÅŸÄ±yorsanÄ±z.LÃ¼tfen ÅŸu dosyaya gidiniz\n",
    "\n",
    "* `ANN\\Tensorler ve OOP\\Self_ve_Ä°nit_FonksiyonlarÄ±.ipynb`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c802aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ANN(nn.Module):\n",
    "    def __init__(self, input_size):\n",
    "        super(ANN,self).__init__()\n",
    "\n",
    "        self.fc1 = nn.Linear(input_size,128)\n",
    "        self.fc2 = nn.Linear(128,64)\n",
    "        self.fc3 = nn.Linear(64,1)\n",
    "\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.sigmoid(self.fc3(x))\n",
    "        \n",
    "        return x "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544b1787",
   "metadata": {},
   "source": [
    "| Parametre     | PyTorchâ€™taki karÅŸÄ±lÄ±ÄŸÄ± | AÃ§Ä±klama                                                 |\n",
    "| ------------- | ---------------------- | -------------------------------------------------------- |\n",
    "| `self`        | Nesne referansÄ±        | KatmanlarÄ± ve parametreleri model nesnesine baÄŸlar       |\n",
    "| `__init__`    | Kurucu fonksiyon       | KatmanlarÄ± ve model parametrelerini baÅŸlatÄ±r             |\n",
    "| `input_size`  | KullanÄ±cÄ± girdisi      | Katman boyutlarÄ±nÄ± belirler, aÄŸÄ±rlÄ±k matrisini oluÅŸturur |\n",
    "| Weight & Bias | KatmanÄ±n parametreleri | Modelin Ã¶ÄŸrenebildiÄŸi deÄŸerler, eÄŸitimle gÃ¼ncellenir     |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69183e3a",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c79ef2f",
   "metadata": {},
   "source": [
    "# PyTorch Modelini GÃ¼Ã§lendirecek Ekstra ModÃ¼ller\n",
    "\n",
    "PyTorch modelimizde kullanabileceÄŸimiz bazÄ± ek modÃ¼ller ve teknikler:\n",
    "\n",
    "---\n",
    "\n",
    "## 1ï¸âƒ£ Dropout\n",
    "- EÄŸitim sÄ±rasÄ±nda bazÄ± nÃ¶ronlarÄ± **rastgele kapatÄ±r**.\n",
    "- AmaÃ§: **Overfittingâ€™i azaltmak**, modelin genellemesini saÄŸlamak.\n",
    "\n",
    "```python\n",
    "self.dropout = nn.Dropout(p=0.2)  # %20 nÃ¶ron rastgele kapatÄ±lÄ±r\n",
    "x = self.relu(self.fc1(x))\n",
    "x = self.dropout(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c11714",
   "metadata": {},
   "source": [
    "## 2ï¸âƒ£ Batch Normalization (BatchNorm)\n",
    "\n",
    "- Katman Ã§Ä±kÄ±ÅŸlarÄ±nÄ± normalize ederek **eÄŸitimi stabil ve hÄ±zlÄ± hale getirir**.\n",
    "- Derin aÄŸlarda Ã¶zellikle **Ã¶ÄŸrenme hÄ±zÄ±nÄ± artÄ±rÄ±r** ve **vanishing/exploding gradient** sorunlarÄ±nÄ± azaltÄ±r.\n",
    "\n",
    "```python\n",
    "self.bn1 = nn.BatchNorm1d(64)  # fc1 Ã§Ä±kÄ±ÅŸÄ± 64 nÃ¶ron\n",
    "x = self.relu(self.bn1(self.fc1(x)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a80473de",
   "metadata": {},
   "source": [
    "## 3ï¸âƒ£ Weight Initialization\n",
    "\n",
    "- Katman aÄŸÄ±rlÄ±klarÄ± genellikle **rastgele baÅŸlatÄ±lÄ±r**, ama kontrol etmek isteyebilirsin.\n",
    "- Ã–rnek: uniform daÄŸÄ±lÄ±m ile baÅŸlatmak\n",
    "\n",
    "```python\n",
    "nn.init.uniform_(self.fc1.weight, a=-0.1, b=0.1)\n",
    "nn.init.zeros_(self.fc1.bias)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91ea70fd",
   "metadata": {},
   "source": [
    "#### nn.init modÃ¼lÃ¼ ile:\n",
    "\n",
    "* uniform_ â†’ belirli aralÄ±kta baÅŸlatma\n",
    "\n",
    "* normal_ â†’ ortalama ve standart sapmalÄ± baÅŸlatma\n",
    "\n",
    "* xavier_uniform_, kaiming_normal_ â†’ derin aÄŸlar iÃ§in Ã¶zel yÃ¶ntemler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8469e958",
   "metadata": {},
   "source": [
    "## 4ï¸âƒ£ Aktivasyon FonksiyonlarÄ±\n",
    "\n",
    "- ReLU dÄ±ÅŸÄ±nda farklÄ± aktivasyonlar deneyebilirsin:\n",
    "  - `nn.Tanh()`\n",
    "  - `nn.LeakyReLU(0.1)`\n",
    "  - `nn.ELU()`\n",
    "  - `nn.Softmax(dim=1)`\n",
    "\n",
    "- Ã–rnek kullanÄ±m:\n",
    "\n",
    "```python\n",
    "self.relu = nn.LeakyReLU(0.1)  # kÃ¼Ã§Ã¼k negatif slope ile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d229faeb",
   "metadata": {},
   "source": [
    "# 5ï¸âƒ£ Ã–zet Tablo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7561f753",
   "metadata": {},
   "source": [
    "| ModÃ¼l/Ã–zellik     | AmaÃ§                                      | KullanÄ±m                           |\n",
    "| ----------------- | ----------------------------------------- | ---------------------------------- |\n",
    "| Dropout           | Overfittingâ€™i azaltmak                    | `nn.Dropout(p)`                    |\n",
    "| BatchNorm         | EÄŸitim stabilitesi ve hÄ±z artÄ±rma         | `nn.BatchNorm1d(n)`                |\n",
    "| Weight Init       | AÄŸÄ±rlÄ±klarÄ± belirli daÄŸÄ±lÄ±m ile baÅŸlatmak | `nn.init.*`                        |\n",
    "| FarklÄ± Aktivasyon | Modelin davranÄ±ÅŸÄ±nÄ± deÄŸiÅŸtirmek           | `nn.ReLU()`, `nn.LeakyReLU()`, ... |\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7e67a80b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class EnhancedANN(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Gizli katman boyutlarÄ± sabit\n",
    "        h1, h2, h3 = 128, 64, 32\n",
    "        layers = []\n",
    "\n",
    "        # 1. Katman\n",
    "        layers.append(nn.Linear(input_size, h1))\n",
    "        layers.append(nn.BatchNorm1d(h1))\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # 2. Katman\n",
    "        layers.append(nn.Linear(h1, h2))\n",
    "        layers.append(nn.BatchNorm1d(h2))\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # 3. Katman\n",
    "        layers.append(nn.Linear(h2, h3))\n",
    "        layers.append(nn.BatchNorm1d(h3))\n",
    "        layers.append(nn.LeakyReLU(0.1))\n",
    "        layers.append(nn.Dropout(dropout_p))\n",
    "\n",
    "        # Ã‡Ä±kÄ±ÅŸ katmanÄ±\n",
    "        layers.append(nn.Linear(h3, output_size))\n",
    "        layers.append(nn.Sigmoid())\n",
    "\n",
    "        self.model = nn.Sequential(*layers)\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4a7005",
   "metadata": {},
   "source": [
    "## Åimdi yukarÄ±da bulunan bu modelin tekrarÄ±nÄ± ve karmaÅŸasÄ±nÄ± dÃ¼zeltelimmm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a38823",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class CleanEnhancedANN(nn.Module):\n",
    "    def __init__(self, input_size, output_size=1, dropout_p=0.2):\n",
    "        super().__init__()\n",
    "\n",
    "        # Katman ve aktivasyonlarÄ± tek bir fonksiyon ile oluÅŸtur\n",
    "        def linear_block(in_features, out_features, dropout):\n",
    "            return nn.Sequential(\n",
    "                nn.Linear(in_features, out_features),\n",
    "                nn.BatchNorm1d(out_features),\n",
    "                nn.LeakyReLU(0.1),\n",
    "                nn.Dropout(dropout)\n",
    "            )\n",
    "        \n",
    "        # KatmanlarÄ± sÄ±rayla ekle\n",
    "        self.model = nn.Sequential(\n",
    "            linear_block(input_size, 128, dropout_p),\n",
    "            linear_block(128, 64, dropout_p),\n",
    "            linear_block(64, 32, dropout_p),\n",
    "            nn.Linear(32, output_size),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Weight initialization\n",
    "        for m in self.model:\n",
    "            if isinstance(m, nn.Linear):\n",
    "                nn.init.xavier_uniform_(m.weight)\n",
    "                nn.init.zeros_(m.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "970e41fd",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (torch_env)",
   "language": "python",
   "name": "torch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
